---
layout: post
title: 論文筆記 Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks
featured-img: cyclegan
mathjax: true
categories: [ICCV, GAN]
---

##  論文出處：[Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593)

關於圖片風格的轉換或是基於特定條件的圖片生成，其實在這之前已經有許多研究。在這之前的生成，主要是利用單個方向且對應於ground turth的GAN生成，像是2016年[
Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/abs/1611.07004) 當中提到的，原理大概解釋一下就是：

*   $X, Y$分別為兩個domain的data
*   Input $x$，先讓生成器 $G$ 生成 $G(x)$ ，而目標就是$G(x)$與 grond truth image越像越好。


文中做出來的實驗結果如下：

![Imgur](https://i.imgur.com/jE6disf.png)

而上述問題是，輸入圖片必須有一個對應的Ground Truth圖片，換句話說，這種轉換其實比較像是把 $X$ 分佈的某張圖轉換至 $Y$ 分佈中的某一張圖片，訓練資料必須是成對(Paired)。而收集不同風格但有對應關係的資料在實際上非常困難。
而Cycle-GAN則是把單向GAN改為雙向結構，這可以讓輸入與輸出是Unpaired，只需要有兩個不同風格的資料。舉例如下：

![Imgur](https://i.imgur.com/ma5JHna.png)

## Introduction

![Imgur](https://i.imgur.com/T9kwz2x.png)

上圖是Cycle-GAN的示意圖。

其中 $G$ 代表從 domain $X$ 轉換至 $Y$ 的生成器 ;
而 $F$ 是從 domain $Y$ 至 $X$ 的生成器。$D$ 為判斷是否為Fake image的判別器，具有兩個：$D_X, D_Y$。 以上 $G, F$ 為共享。
而圖 (b), (c) 中之cycle-consistency loss的目標可以下式表示：

$$x \to G(x) \to F(G(x)) \approx x$$

$$ y \to F(y) \to G(F(y)) \approx y$$

將(b), (c)部分結合，得到循環的結構 (a)

## Formulation
首先定義以下：

Two domain $X, Y$

$$ {\{ x_i \}}_{i=1}^{N} \quad where \quad x_i \in X $$

$$ {\{ y_j \}}_{j=1}^{M} \quad where \quad y_j \in Y $$

Two Dicriminator

$$ D_X, D_Y$$

Two Mapping Function (Generator)

$$G, F$$

### Adversarial Loss

對於 $G : X \to Y $ 以及 $D_Y$ 的 objective，以下表示：

$$ \mathcal L_{GAN}(G, D_Y, X, Y) = \mathbb E_{y \sim p_{data}(y)} [logD_Y(y)] + \mathbb E_{x \sim p_{data}(x)} [log(1 - D_Y(y))]$$ 

$G$ 會生成G會生成 $G(x)$ ， 且盡量讓它近似於從 $Y$ 取出的資料 ; 而 $D_Y$ 則會試圖分辨 $G(x)$ 和 真實分布的資料 $y$ 。 訓練過程中，$G$ 的目標是 minimize 這個 Loss ; 而 D_Y 則是必須 Maximize 這個 Loss。這個Loss Funtion其實可以視為一個二元分類的Loss，詳細推導可以參考GAN相關課程。

同理，對於 $F : Y \to X $ 以及 $D_X$：

$$ \mathcal L_{GAN}(F, D_X, Y, X)$$

運作機制跟前面一樣，這邊不贅述。

### Cycle Consistency Loss

在前面提到的loss，雖然可以讓 $G, F$ 有能力產生風格轉換，但是卻不能保證生成的圖片與原圖是同一個物件。舉例來說，假設 $X$是真實照片，$Y$是油畫照，若一個x為真實車子照片，則極有可能會生成一張圖片 $G(x)$ 是 油畫的人物圖片，這樣沒有達到風格轉換的目的。故本文加入 Cycle Consistency Loss ，限制生成的範圍(reduce the space of possible mapping functions)。

$$ \mathcal L_{cyc}(G,F) = \mathbb E[||F(G(x)) - x||_{1}] + \mathbb E[||G(F(y)) - y||_{1}]$$

可以解釋為，對於一張圖片經過轉換後，要可以reconstruct回原圖，也就是

forward cycle consistency

$$x \to G(x) \to F(G(x)) \approx x$$

backward cycle consistency

$$ y \to F(y) \to G(F(y)) \approx y$$

上述是使用L1 Norm計算差距，文中有提到他們嘗試過不用L1而是用 Adversarial Loss 實驗，但沒有發現效果上的提升。

###  Full Objective
 
將 Adversarial Loss 以及 Cycle Consistency Loss 結合，得到最後的目標函數：

$$\mathcal L(G, F, D_X ,D_Y) = \mathcal L_{GAN}(G, D_Y, X, Y) + \mathcal L_{GAN}(F, D_X, Y, X) + \lambda \mathcal L_{cyc}(G,F)$$

如同一般的GAN，訓練的策略如下：

$$G^*, F^* = arg \operatorname*{min}_{G, F} \operatorname*{max}_{D_X, D_Y} \mathcal L(G, F, D_X ,D_Y)$$

$G^*, F^*$ 就是我們要的生成器，可以對兩個domain作雙向的風格轉換。



## Result

![Imgur](https://i.imgur.com/FrQigAS.png)





