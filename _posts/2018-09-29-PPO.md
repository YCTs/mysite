---
layout: post
title: 論文筆記 Proximal Policy Optimization Algorithms
featured-img: 
mathjax: true
categories: [RL]
---

## 論文出處 [Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)



## Background : Policy Optimization

### Policy Gradient Methods

$$\hat g = \hat{\mathbb E}\big[ \nabla_{\theta} \log \pi_{\theta}(a_t|s_t) \hat {A_t}  \big]$$
*   $\pi_{\theta}$ is a stochastic policy
*   $\hat {A_t}$ is an estimator of the advantage function at timestep $t$.
